#!/usr/bin/env python3
"""
Streamlit ç‰ˆæœ¬çš„å¤šèªè¨€éŸ³æª”è½‰ç¹é«”ä¸­æ–‡å­—å¹•æœå‹™
"""
import streamlit as st
import tempfile
import logging
from pathlib import Path
from datetime import timedelta
import re
import whisper
from deep_translator import GoogleTranslator

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é é¢é…ç½®
st.set_page_config(
    page_title="ğŸ¬ å¤šèªè¨€éŸ³æª”è½‰ç¹ä¸­å­—å¹•",
    page_icon="ğŸ¬",
    layout="wide",
    initial_sidebar_state="expanded"
)

class WhisperSubtitleTranslator:
    def __init__(self):
        self.whisper_model = None
        self.translator = GoogleTranslator(source='auto', target='zh-TW')
        
    @st.cache_resource
    def load_whisper_model(_self, model_size="base"):
        """å‹•æ…‹è¼‰å…¥ Whisper æ¨¡å‹ï¼ˆä½¿ç”¨ Streamlit ç·©å­˜ï¼‰"""
        logger.info(f"è¼‰å…¥ Whisper æ¨¡å‹: {model_size}")
        return whisper.load_model(model_size)
    
    def format_timestamp(self, seconds):
        """å°‡ç§’æ•¸è½‰æ›ç‚º SRT æ™‚é–“æ ¼å¼ (HH:MM:SS,mmm)"""
        td = timedelta(seconds=seconds)
        hours, remainder = divmod(td.total_seconds(), 3600)
        minutes, seconds = divmod(remainder, 60)
        milliseconds = int((seconds % 1) * 1000)
        return f"{int(hours):02d}:{int(minutes):02d}:{int(seconds):02d},{milliseconds:03d}"
    
    def clean_text_for_subtitle(self, text):
        """æ¸…ç†æ–‡å­—ä»¥é©åˆå­—å¹•é¡¯ç¤º"""
        text = re.sub(r'\s+', ' ', text.strip())
        if len(text) > 40:
            words = text.split(' ')
            lines = []
            current_line = ""
            for word in words:
                if len(current_line + " " + word) <= 40:
                    current_line += (" " + word if current_line else word)
                else:
                    if current_line:
                        lines.append(current_line)
                    current_line = word
            if current_line:
                lines.append(current_line)
            text = "\n".join(lines)
        return text
    
    def transcribe_with_timestamps(self, audio_file, model_size="base"):
        """è½‰éŒ„éŸ³é »ä¸¦ä¿ç•™æ™‚é–“æˆ³"""
        try:
            model = self.load_whisper_model(model_size)
            logger.info("é–‹å§‹è½‰éŒ„éŸ³é »...")
            
            with st.status("ğŸ¤ æ­£åœ¨è½‰éŒ„éŸ³é »...", expanded=True) as status:
                st.write("è¼‰å…¥ Whisper æ¨¡å‹...")
                
                # åŠ å…¥éŸ³é »é è™•ç†å’ŒéŒ¯èª¤è™•ç†
                transcribe_options = {
                    "fp16": False,  # å¼·åˆ¶ä½¿ç”¨ FP32 é¿å…å¼µé‡å•é¡Œ
                    "verbose": False,
                    "condition_on_previous_text": False,  # é¿å…é•·éŸ³é »çš„ç´¯ç©éŒ¯èª¤
                }
                
                result = model.transcribe(audio_file, **transcribe_options)
                st.write("æå–èªéŸ³ç‰‡æ®µ...")
                
                segments_data = []
                for segment in result["segments"]:
                    # éæ¿¾æ‰éçŸ­æˆ–ç„¡æ•ˆçš„ç‰‡æ®µ
                    if segment.get('text', '').strip() and (segment['end'] - segment['start']) > 0.1:
                        segments_data.append({
                            'start': segment['start'],
                            'end': segment['end'],
                            'text': segment['text'].strip()
                        })
                
                detected_language = result["language"]
                st.write(f"âœ… è½‰éŒ„å®Œæˆï¼åµæ¸¬èªè¨€: {detected_language}")
                status.update(label="âœ… è½‰éŒ„å®Œæˆ", state="complete")
            
            logger.info(f"è½‰éŒ„å®Œæˆï¼Œåµæ¸¬èªè¨€: {detected_language}ï¼Œå…± {len(segments_data)} å€‹ç‰‡æ®µ")
            return segments_data, detected_language, ""
            
        except Exception as e:
            logger.error(f"è½‰éŒ„éŒ¯èª¤: {str(e)}")
            
            # å˜—è©¦ä½¿ç”¨æ›´å°çš„æ¨¡å‹é‡è©¦
            if model_size != "tiny":
                logger.info("å˜—è©¦ä½¿ç”¨ tiny æ¨¡å‹é‡è©¦...")
                try:
                    return self.transcribe_with_timestamps(audio_file, "tiny")
                except:
                    pass
                    
            return [], "", f"è½‰éŒ„éŒ¯èª¤: {str(e)}"
    
    def translate_to_traditional_chinese(self, text):
        """ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡"""
        try:
            if not text:
                return "æ²’æœ‰æ–‡å­—éœ€è¦ç¿»è­¯", ""
            
            translated_text = self.translator.translate(text)
            
            if translated_text is None:
                translated_text = ""
            elif not isinstance(translated_text, str):
                translated_text = str(translated_text)
            
            return translated_text, ""
            
        except Exception as e:
            logger.error(f"ç¿»è­¯éŒ¯èª¤: {str(e)}")
            return "", str(e)
    
    def generate_srt_content(self, segments_data, translated_segments):
        """ç”Ÿæˆ SRT å­—å¹•æª”å…§å®¹"""
        srt_content = ""
        
        for i, (original_seg, translated_text) in enumerate(zip(segments_data, translated_segments), 1):
            start_time = self.format_timestamp(original_seg['start'])
            end_time = self.format_timestamp(original_seg['end'])
            
            clean_translated = self.clean_text_for_subtitle(translated_text)
            
            srt_content += f"{i}\n"
            srt_content += f"{start_time} --> {end_time}\n"
            srt_content += f"{clean_translated}\n\n"
        
        return srt_content
    
    def process_audio_to_srt(self, audio_file, model_size="base", include_original=False):
        """å®Œæ•´è™•ç†æµç¨‹ï¼šè½‰éŒ„ + ç¿»è­¯ + ç”Ÿæˆ SRT"""
        # æ­¥é©Ÿ 1: è½‰éŒ„éŸ³é »
        segments_data, detected_language, transcribe_error = self.transcribe_with_timestamps(audio_file, model_size)
        
        if transcribe_error:
            raise Exception(f"è½‰éŒ„éŒ¯èª¤: {transcribe_error}")
        
        if not segments_data:
            raise Exception("ç„¡æ³•å¾éŸ³é »ä¸­æå–æ–‡å­—")
        
        # æ­¥é©Ÿ 2: ç¿»è­¯æ¯å€‹ç‰‡æ®µ
        with st.status("ğŸŒ æ­£åœ¨ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡...", expanded=True) as status:
            translated_segments = []
            original_texts = []
            
            progress_bar = st.progress(0)
            total_segments = len(segments_data)
            
            for i, segment in enumerate(segments_data):
                original_text = segment['text']
                original_texts.append(original_text)
                
                translated_text, translate_error = self.translate_to_traditional_chinese(original_text)
                if translate_error:
                    raise Exception(f"ç¿»è­¯éŒ¯èª¤: {translate_error}")
                
                translated_segments.append(translated_text)
                progress_bar.progress((i + 1) / total_segments)
                
            st.write("âœ… ç¿»è­¯å®Œæˆï¼")
            status.update(label="âœ… ç¿»è­¯å®Œæˆ", state="complete")
        
        # æ­¥é©Ÿ 3: ç”Ÿæˆ SRT æª”æ¡ˆ
        with st.status("ğŸ“ ç”Ÿæˆå­—å¹•æª”æ¡ˆ...", expanded=True) as status:
            srt_content = self.generate_srt_content(segments_data, translated_segments)
            st.write("âœ… SRT å­—å¹•æª”ç”Ÿæˆå®Œæˆï¼")
            
            result = {
                'original_texts': original_texts,
                'detected_language': detected_language,
                'translated_segments': translated_segments,
                'srt_content': srt_content,
                'segments_count': len(segments_data)
            }
            
            # å¦‚æœéœ€è¦é›™èªå­—å¹•
            if include_original:
                bilingual_srt = ""
                for i, (original_seg, original_text, translated_text) in enumerate(zip(segments_data, original_texts, translated_segments), 1):
                    start_time = self.format_timestamp(original_seg['start'])
                    end_time = self.format_timestamp(original_seg['end'])
                    
                    clean_original = self.clean_text_for_subtitle(original_text)
                    clean_translated = self.clean_text_for_subtitle(translated_text)
                    
                    bilingual_srt += f"{i}\n"
                    bilingual_srt += f"{start_time} --> {end_time}\n"
                    bilingual_srt += f"{clean_original}\n{clean_translated}\n\n"
                
                result['bilingual_srt'] = bilingual_srt
                st.write("âœ… é›™èªå­—å¹•æª”ç”Ÿæˆå®Œæˆï¼")
            
            status.update(label="âœ… å­—å¹•æª”ç”Ÿæˆå®Œæˆ", state="complete")
        
        return result

# åˆå§‹åŒ–ç¿»è­¯å™¨
@st.cache_resource
def get_translator():
    return WhisperSubtitleTranslator()

def main():
    """ä¸»æ‡‰ç”¨"""
    st.title("ğŸ¬ å¤šèªè¨€éŸ³æª”è½‰ç¹é«”ä¸­æ–‡å­—å¹•æª”")
    st.markdown("---")
    
    # å´é‚Šæ¬„è¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®šé¸é …")
        
        # æ¨¡å‹é¸æ“‡
        model_size = st.selectbox(
            "ğŸ¤– é¸æ“‡ Whisper æ¨¡å‹",
            ["tiny", "base", "small", "medium"],
            index=1,
            help="tiny: æœ€å¿«ä½†æº–ç¢ºåº¦è¼ƒä½ | base: å¹³è¡¡ï¼ˆæ¨è–¦ï¼‰| small/medium: è¼ƒæ…¢ä½†æ›´æº–ç¢º"
        )
        
        # é›™èªå­—å¹•é¸é …
        include_bilingual = st.checkbox(
            "ğŸ“ ç”Ÿæˆé›™èªå­—å¹•",
            help="å‹¾é¸å¾Œæœƒç”ŸæˆåŒ…å«åŸæ–‡å’Œä¸­æ–‡çš„é›™èªå­—å¹•æª”"
        )
        
        st.markdown("---")
        st.markdown("""
        ### ğŸ’¡ åŠŸèƒ½ç‰¹è‰²
        - ğŸŒ æ”¯æŒ 99+ ç¨®èªè¨€è‡ªå‹•åµæ¸¬
        - ğŸ¯ OpenAI Whisper é«˜ç²¾åº¦è½‰éŒ„
        - ğŸ‡¹ğŸ‡¼ è‡ªå‹•ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡
        - ğŸ“‹ ç”Ÿæˆæ¨™æº– SRT å­—å¹•æª”
        - âš¡ å¤šç¨®æ¨¡å‹å¤§å°å¯é¸
        """)
    
    # ä¸»è¦å…§å®¹å€åŸŸ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“ ä¸Šå‚³éŸ³é »æª”æ¡ˆ")
        
        # æª”æ¡ˆä¸Šå‚³
        uploaded_file = st.file_uploader(
            "é¸æ“‡éŸ³é »æª”æ¡ˆ",
            type=['mp3', 'wav', 'm4a', 'flac', 'ogg'],
            help="æ”¯æ´æ ¼å¼ï¼šMP3, WAV, M4A, FLAC, OGG"
        )
        
        if uploaded_file is not None:
            st.success(f"âœ… å·²é¸æ“‡æª”æ¡ˆ: {uploaded_file.name}")
            
            # é¡¯ç¤ºæª”æ¡ˆè³‡è¨Š
            file_size = len(uploaded_file.read())
            uploaded_file.seek(0)  # é‡ç½®æª”æ¡ˆæŒ‡é‡
            st.info(f"æª”æ¡ˆå¤§å°: {file_size / 1024 / 1024:.2f} MB")
            
            # è™•ç†æŒ‰éˆ•
            if st.button("ğŸš€ é–‹å§‹ç”Ÿæˆå­—å¹•", type="primary", use_container_width=True):
                try:
                    translator = get_translator()
                    
                    # ä¿å­˜è‡¨æ™‚æª”æ¡ˆ
                    with tempfile.NamedTemporaryFile(delete=False, suffix=f"_{uploaded_file.name}") as temp_file:
                        temp_file.write(uploaded_file.read())
                        temp_file_path = temp_file.name
                    
                    # è™•ç†éŸ³é »
                    result = translator.process_audio_to_srt(
                        temp_file_path, 
                        model_size=model_size,
                        include_original=include_bilingual
                    )
                    
                    # é¡¯ç¤ºçµæœ
                    st.success("ğŸ‰ å­—å¹•ç”Ÿæˆå®Œæˆï¼")
                    
                    # çµæœè³‡è¨Š
                    col_info1, col_info2, col_info3 = st.columns(3)
                    with col_info1:
                        st.metric("åµæ¸¬èªè¨€", result['detected_language'])
                    with col_info2:
                        st.metric("å­—å¹•ç‰‡æ®µ", result['segments_count'])
                    with col_info3:
                        st.metric("è™•ç†ç‹€æ…‹", "âœ… å®Œæˆ")
                    
                    # ä¸‹è¼‰å€åŸŸ
                    st.markdown("### ğŸ“¥ ä¸‹è¼‰å­—å¹•æª”æ¡ˆ")
                    
                    col_dl1, col_dl2 = st.columns(2)
                    
                    with col_dl1:
                        # ç¹é«”ä¸­æ–‡å­—å¹•ä¸‹è¼‰
                        # æ¸…ç†æª”æ¡ˆåç¨±ï¼Œç§»é™¤å‰¯æª”åå’Œç‰¹æ®Šå­—ç¬¦
                        clean_filename = uploaded_file.name.rsplit('.', 1)[0]
                        clean_filename = re.sub(r'[^\w\s-]', '', clean_filename)
                        
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è¼‰ç¹é«”ä¸­æ–‡å­—å¹• (.srt)",
                            data=result['srt_content'].encode('utf-8'),
                            file_name=f"{clean_filename}_chinese_subtitle.srt",
                            mime="text/plain; charset=utf-8",
                            type="primary"
                        )
                    
                    with col_dl2:
                        # é›™èªå­—å¹•ä¸‹è¼‰
                        if include_bilingual and 'bilingual_srt' in result:
                            clean_filename = uploaded_file.name.rsplit('.', 1)[0]
                            clean_filename = re.sub(r'[^\w\s-]', '', clean_filename)
                            
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è¼‰é›™èªå­—å¹• (.srt)",
                                data=result['bilingual_srt'].encode('utf-8'),
                                file_name=f"{clean_filename}_bilingual_subtitle.srt",
                                mime="text/plain; charset=utf-8",
                                type="secondary"
                            )
                    
                    # é è¦½å…§å®¹
                    with st.expander("ğŸ“ é è¦½è½‰éŒ„å…§å®¹", expanded=False):
                        tab1, tab2 = st.tabs(["åŸæ–‡", "ç¹é«”ä¸­æ–‡"])
                        
                        with tab1:
                            st.text_area(
                                "åŸæ–‡å…§å®¹", 
                                "\n".join(result['original_texts'][:10]) + ("..." if len(result['original_texts']) > 10 else ""),
                                height=200
                            )
                        
                        with tab2:
                            st.text_area(
                                "ç¹é«”ä¸­æ–‡ç¿»è­¯", 
                                "\n".join(result['translated_segments'][:10]) + ("..." if len(result['translated_segments']) > 10 else ""),
                                height=200
                            )
                    
                    # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
                    Path(temp_file_path).unlink()
                    
                except Exception as e:
                    st.error(f"âŒ è™•ç†å¤±æ•—: {str(e)}")
                    logger.error(f"è™•ç†éŒ¯èª¤: {str(e)}")
                    if 'temp_file_path' in locals():
                        try:
                            Path(temp_file_path).unlink()
                        except:
                            pass
    
    with col2:
        st.header("ğŸ“‹ ä½¿ç”¨èªªæ˜")
        
        st.markdown("""
        ### ğŸ”„ è™•ç†æµç¨‹
        1. **ä¸Šå‚³éŸ³é »æª”æ¡ˆ**
           - æ”¯æ´å¤šç¨®æ ¼å¼
           - å»ºè­°æª”æ¡ˆå°æ–¼ 100MB
        
        2. **é¸æ“‡æ¨¡å‹å¤§å°**
           - Base æ¨¡å‹é©åˆå¤§å¤šæ•¸æƒ…æ³
           - æª”æ¡ˆè¶Šå¤§å»ºè­°ç”¨è¶Šå°çš„æ¨¡å‹
        
        3. **é¸æ“‡å­—å¹•é¡å‹**
           - ç´”ä¸­æ–‡ï¼šåªæœ‰ç¹é«”ä¸­æ–‡
           - é›™èªï¼šåŸæ–‡ + ä¸­æ–‡å°ç…§
        
        4. **ä¸‹è¼‰å­—å¹•æª”æ¡ˆ**
           - æ¨™æº– SRT æ ¼å¼
           - å¯ç›´æ¥ç”¨æ–¼å½±ç‰‡æ’­æ”¾å™¨
        
        ### âš ï¸ æ³¨æ„äº‹é …
        - é¦–æ¬¡ä½¿ç”¨éœ€ä¸‹è¼‰æ¨¡å‹
        - è™•ç†æ™‚é–“å–æ±ºæ–¼éŸ³é »é•·åº¦
        - å»ºè­°éŸ³é »å“è³ªè¶Šé«˜è¶Šå¥½
        """)
        
        # æ”¯æ´æ ¼å¼èªªæ˜
        st.markdown("""
        ### ğŸ“ æ”¯æ´æ ¼å¼
        - **éŸ³é »**: MP3, WAV, M4A, FLAC, OGG
        - **èªè¨€**: 99+ ç¨®èªè¨€è‡ªå‹•åµæ¸¬
        - **è¼¸å‡º**: SRT å­—å¹•æª”æ¡ˆ
        """)

if __name__ == "__main__":
    main()